{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Modeling:\n",
    "lets make model for predicting Number of pickups at given 10 mint time interval within perticular cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  ML Problem Formulation:-\n",
    "Time-series forecasting and Regression:-\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selecation:-\n",
    "As for baseline models and some ML model, we will take previous interval pickups( P(t-1), P(t-2).....P(t-n)) as feature to predict pickups at P(t)\n",
    "where n is hyperparameter, need to find best n.\n",
    "<p>In later part we can use other parameter like weeks, weekends, ratio etc feature to improve our model, as of now will try only preveous pickups details</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Performance metrics\n",
    "1. Mean Absolute percentage error.\n",
    "https://en.wikipedia.org/wiki/Mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all used packages\n",
    "import pandas as pd\n",
    "import folium #open street map\n",
    "\n",
    "import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('nbagg') # for more intractive visualization like zoom out\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import rcParams\n",
    "import gpxpy.geo #Get the haversine distance\n",
    "from sklearn.cluster import MiniBatchKMeans, KMeans#Clustering\n",
    "import math\n",
    "import pickle\n",
    "import os\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from lightgbm import LGBMRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "file = \"../output/clean_train_test_yellow_tripdata_2015-01.csv\"\n",
    "jan_data = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jan2019 data row and columns informantion\n",
      "(12371076, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"Jan2019 data row and columns informantion\")\n",
    "print(jan_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_time_unix</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>pickup_cluster</th>\n",
       "      <th>10_min_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.420051e+09</td>\n",
       "      <td>4.00</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.420051e+09</td>\n",
       "      <td>0.80</td>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.420051e+09</td>\n",
       "      <td>1.58</td>\n",
       "      <td>29</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.420051e+09</td>\n",
       "      <td>2.57</td>\n",
       "      <td>38</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.420051e+09</td>\n",
       "      <td>2.50</td>\n",
       "      <td>28</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pickup_time_unix  trip_distance  pickup_cluster  10_min_bin\n",
       "0      1.420051e+09           4.00               8          33\n",
       "1      1.420051e+09           0.80               7          32\n",
       "2      1.420051e+09           1.58              29          32\n",
       "3      1.420051e+09           2.57              38          32\n",
       "4      1.420051e+09           2.50              28          32"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jan_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split:-\n",
    "<p>1-jan-2015 to 19-jan-2015 --> Train</p>\n",
    "20-jan-2016 to 31-jan-2015 --->Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size =  7715505\n",
      "Testing data size =  4655569\n"
     ]
    }
   ],
   "source": [
    "unix_time_20_jan = 1421712000\n",
    "jan_data_train = jan_data[jan_data.pickup_time_unix < 1421712000].copy()\n",
    "jan_data_test = jan_data[jan_data.pickup_time_unix > 1421712000].copy()\n",
    "print(\"Training data size =  \"+str(len(jan_data_train)))\n",
    "print(\"Testing data size =  \"+str(len(jan_data_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_cluster</th>\n",
       "      <th>10_min_bin</th>\n",
       "      <th>trip_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2736</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2737</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2738</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2739</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2740</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pickup_cluster  10_min_bin  trip_count\n",
       "0               0        2736        19.0\n",
       "1               0        2737        13.0\n",
       "2               0        2738        19.0\n",
       "3               0        2739        22.0\n",
       "4               0        2740        27.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Refer:https://www.unixtimestamp.com/\n",
    "start_unix_time = 1420070400\n",
    "#1575158400 : 2019-01-12 00:00:00\n",
    "\n",
    "jan_data_train[\"10_min_bin\"] = jan_data_train[\"pickup_time_unix\"].apply(lambda x : int(abs((x-start_unix_time)/(60*10))))\n",
    "jan_2015_groupby_10m_train = jan_data_train[[\"pickup_cluster\",\"10_min_bin\",\"trip_distance\"]].groupby([\"pickup_cluster\",\"10_min_bin\"]).count()\n",
    "jan_2015_groupby_10m_train.reset_index(inplace=True)\n",
    "jan_2015_groupby_10m_train.rename(columns = {\"trip_distance\":\"trip_count\"},inplace=True)\n",
    "jan_2015_groupby_10m_train[\"trip_count\"] = jan_2015_groupby_10m_train.trip_count.astype(float)\n",
    "\n",
    "jan_data_test[\"10_min_bin\"] = jan_data_test[\"pickup_time_unix\"].apply(lambda x : int(abs((x-start_unix_time)/(60*10))))\n",
    "jan_2015_groupby_10m_test = jan_data_test[[\"pickup_cluster\",\"10_min_bin\",\"trip_distance\"]].groupby([\"pickup_cluster\",\"10_min_bin\"]).count()\n",
    "jan_2015_groupby_10m_test.reset_index(inplace=True)\n",
    "jan_2015_groupby_10m_test.rename(columns = {\"trip_distance\":\"trip_count\"},inplace=True)\n",
    "jan_2015_groupby_10m_test[\"trip_count\"]= jan_2015_groupby_10m_test.trip_count.astype(float)\n",
    "jan_2015_groupby_10m_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Zero Filling:-\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Befor Zero filling Training set size : \"+str(len(jan_2015_groupby_10m_train)))\n",
    "jan_2015_groupby_10m_train\n",
    "new_data_dict =[]\n",
    "data_index = list(jan_2015_groupby_10m_train.groupby([\"pickup_cluster\",\"10_min_bin\"]).count().index.values)\n",
    "for clust in range(30):\n",
    "    for slot in range(2735):\n",
    "        if not (clust,slot) in data_index:\n",
    "            new_data_dict.append([clust,slot,0])\n",
    "\n",
    "new_data = pd.DataFrame(new_data_dict, columns= jan_2015_groupby_10m_train.columns)\n",
    "jan_2015_groupby_10m_train = jan_2015_groupby_10m_train.append(new_data,ignore_index=True)\n",
    "print(\"After Zero filling Training set size : \"+str(len(jan_2015_groupby_10m_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Feature extraction:-\n",
    "Get Feature of P(t) 5 previous interval pickups  as P(t-1), P(t-2),P(t-3), P(t-4),P(t-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(clusters):\n",
    "    val_feature = []\n",
    "    val_label = []\n",
    "    for grp, val_df in clusters:\n",
    "        val_df.sort_values(\"10_min_bin\",inplace = True)\n",
    "        val_feature.extend(np.array([ list(val_df.trip_count[i:i+5]) for i in range(len(val_df)-6)]))\n",
    "        val_label.extend( [val_df.trip_count.iloc[i+6] for i in range(len(val_df)-6)])\n",
    "    return val_feature, val_label\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_train, y_train = get_features(jan_2015_groupby_10m_train.groupby(\"pickup_cluster\"))\n",
    "x_test, y_test = get_features(jan_2015_groupby_10m_test.groupby(\"pickup_cluster\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mean absolute percentage error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean absolute percentage error\n",
    "#def mean_absolute_percentage_error(y_true, y_pred): \n",
    "#    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "#    return np.mean(np.abs((y_true - y_pred) / (y_true+0.00001)))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean absolute percentage error\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    y_true = np.mean(y_true)\n",
    "    return np.mean(np.abs((y_true - y_pred) /y_true))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression --> Train MARE : 78.44930023588755\n",
      "Linear Regression --> Test MARE : 78.38374686942757\n"
     ]
    }
   ],
   "source": [
    "lr_reg=LinearRegression().fit(x_train, y_train)\n",
    "\n",
    "y_pred = lr_reg.predict(x_test)\n",
    "lr_test_predictions = [round(value) for value in y_pred]\n",
    "y_pred = lr_reg.predict(x_train)\n",
    "lr_train_predictions = [round(value) for value in y_pred]\n",
    "\n",
    "lr_mape_train = mean_absolute_percentage_error(y_train,lr_train_predictions)\n",
    "lr_mape_test = mean_absolute_percentage_error(y_test,lr_test_predictions)\n",
    "print(\"Linear Regression --> Train MAPE : \"+str(lr_mape_train))\n",
    "print(\"Linear Regression --> Test MAPE : \"+str(lr_mape_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor --> Train MARE : 79.16781613968288\n",
      "Random Forest Regressor --> Test MARE : 79.03402484176057\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(max_features='sqrt',min_samples_leaf=4,min_samples_split=3,n_estimators=500, n_jobs=-1)\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(x_test)\n",
    "rf_test_predictions = [round(value) for value in y_pred]\n",
    "y_pred = rf.predict(x_train)\n",
    "rf_train_predictions = [round(value) for value in y_pred]\n",
    "\n",
    "rf_mape_train = mean_absolute_percentage_error(y_train,rf_train_predictions)\n",
    "rf_mape_test = mean_absolute_percentage_error(y_test,rf_test_predictions)\n",
    "print(\"Random Forest Regressor --> Train MAPE : \"+str(rf_mape_train))\n",
    "print(\"Random Forest Regressor --> Test MAPE : \"+str(rf_mape_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. XGBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Regressor --> Train MARE : 79.04502153396606\n",
      "XGB Regressor --> Test MARE : 79.03506755828857\n"
     ]
    }
   ],
   "source": [
    "x_model = xgb.XGBRegressor(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=5,\n",
    " min_child_weight=3,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " reg_alpha=200, reg_lambda=200,\n",
    " colsample_bytree=0.8,nthread=4)\n",
    "x_model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = x_model.predict(x_test)\n",
    "xgb_test_predictions = [round(value) for value in y_pred]\n",
    "y_pred = x_model.predict(x_train)\n",
    "xgb_train_predictions = [round(value) for value in y_pred]\n",
    "\n",
    "xgb_mape_train = mean_absolute_percentage_error(y_train,xgb_train_predictions)\n",
    "xgb_mape_test = mean_absolute_percentage_error(y_test,xgb_test_predictions)\n",
    "print(\"XGB Regressor --> Train MAPE : \"+str(xgb_mape_train))\n",
    "print(\"XGB Regressor --> Test MAPE : \"+str(xgb_mape_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Light GBM Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression --> Train MARE : 78.65115363295799\n",
      "Linear Regression --> Test MARE : 78.58739364218933\n"
     ]
    }
   ],
   "source": [
    "lgbm = LGBMRegressor(\n",
    " learning_rate =0.01,\n",
    " n_estimators=1000,\n",
    " max_depth=2,\n",
    " min_child_weight=3,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " reg_alpha=200, reg_lambda=200,\n",
    " colsample_bytree=0.8,nthread=4)\n",
    "lgbm.fit(x_train, y_train)\n",
    "\n",
    "y_pred = lgbm.predict(x_test)\n",
    "lgbm_test_predictions = [round(value) for value in y_pred]\n",
    "y_pred = lgbm.predict(x_train)\n",
    "lgbm_train_predictions = [round(value) for value in y_pred]\n",
    "\n",
    "lgbm_mape_train = mean_absolute_percentage_error(y_train,lgbm_train_predictions)\n",
    "lgbm_mape_test = mean_absolute_percentage_error(y_test,lgbm_test_predictions)\n",
    "print(\"LGBM Regressor --> Train MAPE : \"+str(lgbm_mape_train))\n",
    "print(\"LGBM Regressor --> Test MAPE : \"+str(lgbm_mape_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model:-\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_model_file = \"../model/lgbm_model.sav\"\n",
    "with open(lgbm_model_file,'wb') as file_obj:\n",
    "    pickle.dump(lgbm, file_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Observation:-\n",
    "\n",
    "<p>1.We can see Best MAPE we got from Light GBM model.</p>\n",
    "<p>2. But still its looks high, we can go for hyperparameter tuning to improve model performance.</p>\n",
    "<p>3. And Here we are using just one month data with feature as previous 5 interval, if want to improve, we can add some more month data for feature Extraction</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Lets see some of predicated outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[34.0, 53.0, 50.0, 62.0, 77.0, 70.0, 100.0, 96.0, 111.0, 117.0]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[26.0, 32.0, 35.0, 49.0, 53.0, 61.0, 73.0, 72.0, 91.0, 96.0]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_test_predictions[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  Observation:-\n",
    "quite less than actuals pickups count, its still ok.\n",
    "<p>We will try to solve using Deep learning model like LSTM in future</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thanks for reading my work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
